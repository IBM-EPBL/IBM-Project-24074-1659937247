{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ee7e33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "becc855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator (rescale=1./255, shear_range=0.1,zoom_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10968b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7a367ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 979 images belonging to 3 classes.\n",
      "Found 171 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\"C:\\\\Users\\\\ssdha\\\\Downloads\\\\Car damage-20221030T082416Z-001\\\\Car damage\\\\body\\\\training\",target_size = (224, 224),batch_size = 10,class_mode= 'categorical')\n",
    "test_set = test_datagen.flow_from_directory(\"C:\\\\Users\\\\ssdha\\\\Downloads\\\\Car damage-20221030T082416Z-001\\\\Car damage\\\\body\\\\validation\",target_size = (224, 224),batch_size = 10,class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c4a7b78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "99e1154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSize=[224,224]\n",
    "Vgg = VGG16(input_shape=imageSize+[3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "443d4412",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in Vgg.layers:\n",
    "    layer.trainable =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3b3f9738",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Flatten()(Vgg.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "55a20a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(3, activation='softmax')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1c128030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=Vgg.input,outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bce95c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d7d9b742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssdha\\AppData\\Local\\Temp\\ipykernel_15632\\1270631010.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "97/97 [==============================] - 644s 7s/step - loss: 1.2665 - acc: 0.5315 - val_loss: 0.8390 - val_acc: 0.6765\n",
      "Epoch 2/25\n",
      "97/97 [==============================] - 447s 5s/step - loss: 0.7126 - acc: 0.7162 - val_loss: 0.9837 - val_acc: 0.6412\n",
      "Epoch 3/25\n",
      "97/97 [==============================] - 469s 5s/step - loss: 0.4864 - acc: 0.8070 - val_loss: 0.9016 - val_acc: 0.6765\n",
      "Epoch 4/25\n",
      "97/97 [==============================] - 474s 5s/step - loss: 0.3601 - acc: 0.8607 - val_loss: 1.0623 - val_acc: 0.6647\n",
      "Epoch 5/25\n",
      "97/97 [==============================] - 474s 5s/step - loss: 0.2620 - acc: 0.9112 - val_loss: 0.9379 - val_acc: 0.6529\n",
      "Epoch 6/25\n",
      "97/97 [==============================] - 461s 5s/step - loss: 0.2063 - acc: 0.9267 - val_loss: 0.9162 - val_acc: 0.7000\n",
      "Epoch 7/25\n",
      "97/97 [==============================] - 484s 5s/step - loss: 0.1723 - acc: 0.9474 - val_loss: 0.9836 - val_acc: 0.6588\n",
      "Epoch 8/25\n",
      "97/97 [==============================] - 475s 5s/step - loss: 0.1129 - acc: 0.9732 - val_loss: 1.1504 - val_acc: 0.7059\n",
      "Epoch 9/25\n",
      "97/97 [==============================] - 469s 5s/step - loss: 0.1475 - acc: 0.9587 - val_loss: 1.0588 - val_acc: 0.6824\n",
      "Epoch 10/25\n",
      "97/97 [==============================] - 400s 4s/step - loss: 0.1042 - acc: 0.9742 - val_loss: 1.0563 - val_acc: 0.6824\n",
      "Epoch 11/25\n",
      "97/97 [==============================] - 377s 4s/step - loss: 0.1063 - acc: 0.9742 - val_loss: 1.1962 - val_acc: 0.6647\n",
      "Epoch 12/25\n",
      "97/97 [==============================] - 378s 4s/step - loss: 0.0908 - acc: 0.9825 - val_loss: 1.1616 - val_acc: 0.6647\n",
      "Epoch 13/25\n",
      "97/97 [==============================] - 377s 4s/step - loss: 0.0535 - acc: 0.9917 - val_loss: 1.0477 - val_acc: 0.6941\n",
      "Epoch 14/25\n",
      "97/97 [==============================] - 378s 4s/step - loss: 0.1024 - acc: 0.9670 - val_loss: 1.1616 - val_acc: 0.6765\n",
      "Epoch 15/25\n",
      "97/97 [==============================] - 381s 4s/step - loss: 0.0824 - acc: 0.9804 - val_loss: 1.1187 - val_acc: 0.6941\n",
      "Epoch 16/25\n",
      "97/97 [==============================] - 381s 4s/step - loss: 0.0867 - acc: 0.9773 - val_loss: 1.1520 - val_acc: 0.7059\n",
      "Epoch 17/25\n",
      "97/97 [==============================] - 378s 4s/step - loss: 0.1146 - acc: 0.9701 - val_loss: 1.1497 - val_acc: 0.7118\n",
      "Epoch 18/25\n",
      "97/97 [==============================] - 376s 4s/step - loss: 0.0460 - acc: 0.9866 - val_loss: 1.1894 - val_acc: 0.7000\n",
      "Epoch 19/25\n",
      "97/97 [==============================] - 375s 4s/step - loss: 0.1040 - acc: 0.9608 - val_loss: 1.2113 - val_acc: 0.6941\n",
      "Epoch 20/25\n",
      "97/97 [==============================] - 374s 4s/step - loss: 0.0847 - acc: 0.9752 - val_loss: 1.3637 - val_acc: 0.6588\n",
      "Epoch 21/25\n",
      "97/97 [==============================] - 375s 4s/step - loss: 0.0919 - acc: 0.9773 - val_loss: 1.3282 - val_acc: 0.6647\n",
      "Epoch 22/25\n",
      "97/97 [==============================] - 376s 4s/step - loss: 0.0683 - acc: 0.9773 - val_loss: 1.4772 - val_acc: 0.6647\n",
      "Epoch 23/25\n",
      "97/97 [==============================] - 377s 4s/step - loss: 0.0301 - acc: 0.9948 - val_loss: 1.3603 - val_acc: 0.6706\n",
      "Epoch 24/25\n",
      "97/97 [==============================] - 455s 5s/step - loss: 0.0486 - acc: 0.9897 - val_loss: 1.3309 - val_acc: 0.6706\n",
      "Epoch 25/25\n",
      "97/97 [==============================] - 478s 5s/step - loss: 0.0961 - acc: 0.9742 - val_loss: 1.4309 - val_acc: 0.6824\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#fit the model\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=25,\n",
    "  steps_per_epoch=979//10,\n",
    "  validation_steps=171//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "550db697",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('body.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "61b21b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b03871d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('body.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dd7e094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function, which is used to predict, so need some preprocessing \n",
    "def detect (frame):\n",
    "    img = cv2.resize(frame, (224,224)) #resizing the image to model trained image size\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # uploaded image is in the form of BGR, so convert to RGB\n",
    "    # scaling need to be done\n",
    "    if(np.max(img)>1):\n",
    "        img=img/255.0\n",
    "    img= np.array([img]) #then to array fpormat \n",
    "    prediction = model.predict(img)\n",
    "    print(prediction)\n",
    "    label=[\"front\", \"rear\",\"side\"]\n",
    "    preds =label [np.argmax(prediction)]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7c9e9f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ada3e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12108\\1175456649.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\ssdha\\\\Downloads\\\\Car damage-20221030T082416Z-001\\\\Car damage\\\\body\\\\validation\\\\01-rear\\\\0019.JPEG\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "data=\"C:\\\\Users\\\\ssdha\\\\Downloads\\\\Car damage-20221030T082416Z-001\\\\Car damage\\\\body\\\\validation\\\\01-rear\\\\0019.JPEG\"\n",
    "image=cv2.imread(data)\n",
    "print(detect(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9697422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n",
      "[[3.996842e-02 9.600312e-01 3.556172e-07]]\n",
      "rear\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89c410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462c2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452b477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26db2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
