{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee7e33fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4352e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator (rescale=1./255, shear_range=0.1,zoom_range=0.1, horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1234b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "931aef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 979 images belonging to 3 classes.\n",
      "Found 171 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\"C:\\\\Users\\\\ssdha\\\\Downloads\\\\Car damage-20221030T082416Z-001\\\\Car damage\\\\level\\\\training\",target_size = (224, 224),batch_size = 10,class_mode= 'categorical')\n",
    "test_set = test_datagen.flow_from_directory(\"C:\\\\Users\\\\ssdha\\\\Downloads\\\\Car damage-20221030T082416Z-001\\\\Car damage\\\\level\\\\validation\",target_size = (224, 224),batch_size = 10,class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fbfdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae1b6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSize=[224,224]\n",
    "Vgg = VGG16(input_shape=imageSize+[3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34140c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in Vgg.layers:\n",
    "    layer.trainable =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fbf9a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Flatten()(Vgg.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e9202d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(3, activation='softmax')(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "681811e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=Vgg.input,outputs=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3da38922",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be7132fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssdha\\AppData\\Local\\Temp\\ipykernel_16232\\1270631010.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "97/97 [==============================] - 615s 6s/step - loss: 1.2952 - acc: 0.5511 - val_loss: 0.9781 - val_acc: 0.6176\n",
      "Epoch 2/25\n",
      "97/97 [==============================] - 469s 5s/step - loss: 0.7509 - acc: 0.7028 - val_loss: 1.1403 - val_acc: 0.6000\n",
      "Epoch 3/25\n",
      "97/97 [==============================] - 469s 5s/step - loss: 0.6111 - acc: 0.7771 - val_loss: 1.3184 - val_acc: 0.5588\n",
      "Epoch 4/25\n",
      "97/97 [==============================] - 475s 5s/step - loss: 0.4141 - acc: 0.8235 - val_loss: 1.3696 - val_acc: 0.5882\n",
      "Epoch 5/25\n",
      "97/97 [==============================] - 472s 5s/step - loss: 0.3886 - acc: 0.8493 - val_loss: 1.1504 - val_acc: 0.6059\n",
      "Epoch 6/25\n",
      "97/97 [==============================] - 462s 5s/step - loss: 0.2875 - acc: 0.8927 - val_loss: 1.3244 - val_acc: 0.6118\n",
      "Epoch 7/25\n",
      "97/97 [==============================] - 486s 5s/step - loss: 0.2268 - acc: 0.9205 - val_loss: 1.1829 - val_acc: 0.6294\n",
      "Epoch 8/25\n",
      "97/97 [==============================] - 476s 5s/step - loss: 0.1855 - acc: 0.9309 - val_loss: 1.4247 - val_acc: 0.5941\n",
      "Epoch 9/25\n",
      "97/97 [==============================] - 471s 5s/step - loss: 0.1278 - acc: 0.9587 - val_loss: 1.2675 - val_acc: 0.6235\n",
      "Epoch 10/25\n",
      "97/97 [==============================] - 401s 4s/step - loss: 0.1080 - acc: 0.9628 - val_loss: 1.1711 - val_acc: 0.6471\n",
      "Epoch 11/25\n",
      "97/97 [==============================] - 377s 4s/step - loss: 0.0990 - acc: 0.9721 - val_loss: 1.1438 - val_acc: 0.6412\n",
      "Epoch 12/25\n",
      "97/97 [==============================] - 377s 4s/step - loss: 0.0584 - acc: 0.9917 - val_loss: 1.1807 - val_acc: 0.6235\n",
      "Epoch 13/25\n",
      "97/97 [==============================] - 377s 4s/step - loss: 0.0810 - acc: 0.9680 - val_loss: 1.2833 - val_acc: 0.6176\n",
      "Epoch 14/25\n",
      "97/97 [==============================] - 377s 4s/step - loss: 0.0712 - acc: 0.9804 - val_loss: 1.2742 - val_acc: 0.6412\n",
      "Epoch 15/25\n",
      "97/97 [==============================] - 380s 4s/step - loss: 0.0468 - acc: 0.9938 - val_loss: 1.1943 - val_acc: 0.6529\n",
      "Epoch 16/25\n",
      "97/97 [==============================] - 381s 4s/step - loss: 0.0527 - acc: 0.9886 - val_loss: 1.3129 - val_acc: 0.6118\n",
      "Epoch 17/25\n",
      "97/97 [==============================] - 376s 4s/step - loss: 0.0517 - acc: 0.9907 - val_loss: 1.3700 - val_acc: 0.6412\n",
      "Epoch 18/25\n",
      "97/97 [==============================] - 378s 4s/step - loss: 0.0397 - acc: 0.9948 - val_loss: 1.2933 - val_acc: 0.6588\n",
      "Epoch 19/25\n",
      "97/97 [==============================] - 377s 4s/step - loss: 0.0486 - acc: 0.9876 - val_loss: 1.3445 - val_acc: 0.6176\n",
      "Epoch 20/25\n",
      "97/97 [==============================] - 377s 4s/step - loss: 0.0306 - acc: 0.9938 - val_loss: 1.4859 - val_acc: 0.6353\n",
      "Epoch 21/25\n",
      "97/97 [==============================] - 378s 4s/step - loss: 0.0246 - acc: 0.9959 - val_loss: 1.3050 - val_acc: 0.6588\n",
      "Epoch 22/25\n",
      "97/97 [==============================] - 376s 4s/step - loss: 0.0492 - acc: 0.9897 - val_loss: 1.3796 - val_acc: 0.6412\n",
      "Epoch 23/25\n",
      "97/97 [==============================] - 375s 4s/step - loss: 0.0333 - acc: 0.9938 - val_loss: 1.3668 - val_acc: 0.6588\n",
      "Epoch 24/25\n",
      "97/97 [==============================] - 457s 5s/step - loss: 0.0365 - acc: 0.9897 - val_loss: 1.6449 - val_acc: 0.5824\n",
      "Epoch 25/25\n",
      "97/97 [==============================] - 477s 5s/step - loss: 0.0499 - acc: 0.9856 - val_loss: 1.5680 - val_acc: 0.5941\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "#fit the model\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=25,\n",
    "  steps_per_epoch=979//10,\n",
    "  validation_steps=171//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3cbf896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('level.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b5a910cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac12a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('level.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9bf4b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function, which is used to predict, so need some preprocessing \n",
    "def detect (frame):\n",
    "    img = cv2.resize(frame, (224,224)) #resizing the image to model trained image size\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # uploaded image is in the form of BGR, so convert to RGB\n",
    "    # scaling need to be done\n",
    "    if(np.max(img)>1):\n",
    "        img=img/255.0\n",
    "    img= np.array([img]) #then to array fpormat \n",
    "    prediction = model.predict(img)\n",
    "    print(prediction)\n",
    "    label=[\"minor\",\"moderate\",\"severe\"]\n",
    "    preds =label [np.argmax(prediction)]\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5dd51620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1bcc32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"C:\\\\Users\\\\ssdha\\\\Downloads\\\\Car damage-20221030T082416Z-001\\\\Car damage\\\\level\\\\validation\\\\03-severe\\\\0048.JPEG\"\n",
    "image=cv2.imread(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "689c985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n",
      "[[4.0794319e-08 2.5020361e-05 9.9997497e-01]]\n",
      "severe\n"
     ]
    }
   ],
   "source": [
    "print(detect(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a25db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c183c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54f956a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f2f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
